{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ea95e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\antony\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\antony\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 2)) (3.8.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\antony\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\antony\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\antony\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 5)) (0.13.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Antony\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for re\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20e682dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import uniform, randint\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c007c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/processed/train_cleaned.csv')\n",
    "test = pd.read_csv('data/processed/test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b49b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'Age','Fare']\n",
    "drop_test = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Age','Fare']\n",
    "\n",
    "\n",
    "y_train = train['Survived']\n",
    "X = train.drop(drop_columns, axis=1)\n",
    "X_test = test.drop(drop_test, axis=1)\n",
    "x_train = X.values # Creates an array of the train data\n",
    "x_test = X_test.values \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e939633",
   "metadata": {},
   "source": [
    "## Grid Search CV\n",
    "\n",
    "Principe : on définit un ensemble de valeurs possibles pour chaque hyperparamètre, et on teste toutes les combinaisons.\n",
    "\n",
    "Avantage : simple à implémenter, bonne couverture.\n",
    "\n",
    "Inconvénient : très coûteux en temps de calcul, surtout avec de nombreux paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5094f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:46:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Score sur validation croisée : 0.8439955106621774\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'min_child_weight': [1, 3],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1],\n",
    "}\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Score sur validation croisée :\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9bccd1",
   "metadata": {},
   "source": [
    "**Meilleurs paramètres selon GridSearch CV:**\n",
    "\n",
    "| Paramètre | Valeur |\n",
    "|-----------|--------|\n",
    "| colsample_bytree | 0.8 |\n",
    "| gamma | 0 |\n",
    "| learning_rate | 0.1 |\n",
    "| max_depth | 9 |\n",
    "| min_child_weight | 3 |\n",
    "| n_estimators | 300 |\n",
    "| subsample | 0.8 |\n",
    "\n",
    "Using 3-fold CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78b9868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9001122334455668\n",
      "Confusion Matrix:\n",
      " [[522  27]\n",
      " [ 62 280]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       549\n",
      "           1       0.91      0.82      0.86       342\n",
      "\n",
      "    accuracy                           0.90       891\n",
      "   macro avg       0.90      0.88      0.89       891\n",
      "weighted avg       0.90      0.90      0.90       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    "    n_estimators= 300,\n",
    "    max_depth= 9,\n",
    "    min_child_weight= 3,\n",
    "    gamma=0.9,                        \n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread= -1,\n",
    "    scale_pos_weight=1).fit(x_train, y_train)\n",
    "\n",
    "xgb_predictions = gbm.predict(x_test)\n",
    "predictions_train = gbm.predict(x_train)\n",
    "\n",
    "PassengerId = test['PassengerId']\n",
    "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId, 'Survived': xgb_predictions })\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "accuracy = accuracy_score(train['Survived'], predictions_train)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(train['Survived'], predictions_train))\n",
    "print(\"Classification Report:\\n\", classification_report(train['Survived'], predictions_train))\n",
    "\n",
    "StackingSubmission.to_csv('data/submissions/XGB_GridSearch.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb82ceb",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "Principe : au lieu de tester toutes les combinaisons, on en teste un nombre fixe choisi aléatoirement dans l’espace des hyperparamètres.\n",
    "\n",
    "Avantage : souvent plus efficace que grid search pour un budget donné ; explore mieux quand certains hyperparamètres sont plus importants que d'autres.\n",
    "\n",
    "Inconvénient : moins systématique, résultats variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52a02d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:46:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres : {'colsample_bytree': 0.7582821860536126, 'gamma': 0.021282275099978296, 'learning_rate': 0.1290351481641665, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 242, 'reg_alpha': 0.375582952639944, 'reg_lambda': 0.093981939840869, 'subsample': 0.8734840422988521}\n",
      "Score sur validation croisée : 0.8372615039281706\n"
     ]
    }
   ],
   "source": [
    "# Grille aléatoire\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'subsample': uniform(0.7, 0.3),        \n",
    "    'colsample_bytree': uniform(0.7, 0.3),    \n",
    "    'gamma': uniform(0, 0.3),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1),\n",
    "}\n",
    "\n",
    "# 4. RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,             # nombre d'itérations aléatoires\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 5. Entraîner\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# 6. Résultats\n",
    "print(\"Meilleurs paramètres :\", random_search.best_params_)\n",
    "print(\"Score sur validation croisée :\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1188088",
   "metadata": {},
   "source": [
    "**Meilleurs paramètres selon RandomSearch CV**\n",
    "\n",
    "| Paramètre | Valeur |\n",
    "|-----------|--------|\n",
    "| colsample_bytree | 0.758 |\n",
    "| gamma | 0.021 |\n",
    "| learning_rate | 0.129 |\n",
    "| max_depth | 8 |\n",
    "| min_child_weight | 3 |\n",
    "| n_estimators | 242 |\n",
    "| reg_alpha | 0.376 |\n",
    "| reg_lambda | 0.094 |\n",
    "| subsample | 0.873 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed5d86b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9248035914702581\n",
      "Confusion Matrix:\n",
      " [[529  20]\n",
      " [ 47 295]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       549\n",
      "           1       0.94      0.86      0.90       342\n",
      "\n",
      "    accuracy                           0.92       891\n",
      "   macro avg       0.93      0.91      0.92       891\n",
      "weighted avg       0.93      0.92      0.92       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(\n",
    "    learning_rate = 0.129,\n",
    "    n_estimators= 242,\n",
    "    max_depth= 8,\n",
    "    min_child_weight= 3,\n",
    "    gamma=0.021,                        \n",
    "    subsample=0.873,\n",
    "    colsample_bytree=0.758,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread= -1,\n",
    "    scale_pos_weight=1).fit(x_train, y_train)\n",
    "\n",
    "xgb_predictions = gbm.predict(x_test)\n",
    "predictions_train = gbm.predict(x_train)\n",
    "\n",
    "PassengerId = test['PassengerId']\n",
    "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId, 'Survived': xgb_predictions })\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "accuracy = accuracy_score(train['Survived'], predictions_train)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(train['Survived'], predictions_train))\n",
    "print(\"Classification Report:\\n\", classification_report(train['Survived'], predictions_train))\n",
    "\n",
    "StackingSubmission.to_csv('data/submissions/XGB_RandomSearch.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b0bfa",
   "metadata": {},
   "source": [
    "## Bayesian Optimization\n",
    "\n",
    "Principe : on modélise la fonction de performance du modèle en fonction des hyperparamètres (souvent via un Gaussian Process), et on choisit les hyperparamètres à tester de manière intelligente (exploration/exploitation).\n",
    "\n",
    "Avantage : beaucoup plus efficace quand le coût d'entraînement est élevé.\n",
    "\n",
    "Inconvénient : plus complexe à mettre en œuvre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9d804cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 13:58:49,493] A new study created in memory with name: no-name-7158c1f3-6c4f-4de5-9aa2-aa1ce92734cc\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:49,942] Trial 0 finished with value: 0.8215488215488215 and parameters: {'n_estimators': 139, 'learning_rate': 0.07241186497959771, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.7678648313806435, 'colsample_bytree': 0.8824202105632171, 'gamma': 0.2888372390673911, 'reg_alpha': 0.7748681494958238, 'reg_lambda': 0.8344631502205396}. Best is trial 0 with value: 0.8215488215488215.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:50,525] Trial 1 finished with value: 0.8148148148148149 and parameters: {'n_estimators': 256, 'learning_rate': 0.07443816411215334, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.8633431436973175, 'colsample_bytree': 0.8297126302494623, 'gamma': 0.10596719213492557, 'reg_alpha': 0.5283347063600444, 'reg_lambda': 0.17208471979886253}. Best is trial 0 with value: 0.8215488215488215.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:51,086] Trial 2 finished with value: 0.8013468013468014 and parameters: {'n_estimators': 352, 'learning_rate': 0.27767062252144775, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.7301711752420711, 'colsample_bytree': 0.885044118143682, 'gamma': 0.016140142878653164, 'reg_alpha': 0.022761451267704458, 'reg_lambda': 0.9988577535683923}. Best is trial 0 with value: 0.8215488215488215.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:51,380] Trial 3 finished with value: 0.8249158249158249 and parameters: {'n_estimators': 219, 'learning_rate': 0.29704266632652465, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.930509823618016, 'colsample_bytree': 0.907922724924656, 'gamma': 0.2796092022445172, 'reg_alpha': 0.12015664888002087, 'reg_lambda': 0.9979503440751599}. Best is trial 3 with value: 0.8249158249158249.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:51,798] Trial 4 finished with value: 0.8148148148148149 and parameters: {'n_estimators': 284, 'learning_rate': 0.18780474771385047, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.8959941769001297, 'colsample_bytree': 0.880552993901481, 'gamma': 0.011588265069642412, 'reg_alpha': 0.9528532083693957, 'reg_lambda': 0.7256434506781926}. Best is trial 3 with value: 0.8249158249158249.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:52,464] Trial 5 finished with value: 0.8305274971941637 and parameters: {'n_estimators': 260, 'learning_rate': 0.10994044700779738, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.8673258230588612, 'colsample_bytree': 0.8409265096060319, 'gamma': 0.015014520407365438, 'reg_alpha': 0.4516711666770954, 'reg_lambda': 0.5171096794518715}. Best is trial 5 with value: 0.8305274971941637.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:52,856] Trial 6 finished with value: 0.8226711560044894 and parameters: {'n_estimators': 187, 'learning_rate': 0.01575048414913721, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.755702843726231, 'colsample_bytree': 0.9478342229685406, 'gamma': 0.054644790337151194, 'reg_alpha': 0.877434593392265, 'reg_lambda': 0.6514877432190461}. Best is trial 5 with value: 0.8305274971941637.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:53,202] Trial 7 finished with value: 0.8294051627384961 and parameters: {'n_estimators': 273, 'learning_rate': 0.2251622238310763, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.995539373195582, 'colsample_bytree': 0.9366992487411683, 'gamma': 0.1341848488136101, 'reg_alpha': 0.13745745967597156, 'reg_lambda': 0.4954104771661386}. Best is trial 5 with value: 0.8305274971941637.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:53,520] Trial 8 finished with value: 0.8114478114478114 and parameters: {'n_estimators': 228, 'learning_rate': 0.08548966497182932, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.9500566522325764, 'colsample_bytree': 0.7048664463034667, 'gamma': 0.04587135019100974, 'reg_alpha': 0.993120906315477, 'reg_lambda': 0.29269397083977433}. Best is trial 5 with value: 0.8305274971941637.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:53,868] Trial 9 finished with value: 0.8204264870931537 and parameters: {'n_estimators': 248, 'learning_rate': 0.18475822443917683, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.8220556750373319, 'colsample_bytree': 0.7943757980282516, 'gamma': 0.2466128268939221, 'reg_alpha': 0.5826049373228444, 'reg_lambda': 0.4345064420376641}. Best is trial 5 with value: 0.8305274971941637.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:54,775] Trial 10 finished with value: 0.8237934904601572 and parameters: {'n_estimators': 395, 'learning_rate': 0.1262442356381912, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8231227161723801, 'colsample_bytree': 0.9945733055582959, 'gamma': 0.19859868018335847, 'reg_alpha': 0.3254172683110505, 'reg_lambda': 0.03619981137894057}. Best is trial 5 with value: 0.8305274971941637.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:55,351] Trial 11 finished with value: 0.8395061728395062 and parameters: {'n_estimators': 310, 'learning_rate': 0.2329112998533126, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9763067300058655, 'colsample_bytree': 0.797344390757421, 'gamma': 0.13414677435272512, 'reg_alpha': 0.277881354677674, 'reg_lambda': 0.5418048802503875}. Best is trial 11 with value: 0.8395061728395062.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:55,787] Trial 12 finished with value: 0.8338945005611672 and parameters: {'n_estimators': 320, 'learning_rate': 0.24378489069798243, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9872311569935772, 'colsample_bytree': 0.7738017826816612, 'gamma': 0.1823371747639281, 'reg_alpha': 0.32370791354407125, 'reg_lambda': 0.3664028861408794}. Best is trial 11 with value: 0.8395061728395062.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:56,213] Trial 13 finished with value: 0.8417508417508417 and parameters: {'n_estimators': 333, 'learning_rate': 0.23376950023839504, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9983897676224504, 'colsample_bytree': 0.7660241891583894, 'gamma': 0.17234022446250194, 'reg_alpha': 0.31359396605184414, 'reg_lambda': 0.2702191086122473}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:56,750] Trial 14 finished with value: 0.8215488215488215 and parameters: {'n_estimators': 326, 'learning_rate': 0.23828432923776977, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.9549982852355491, 'colsample_bytree': 0.732240158124886, 'gamma': 0.10717136863313233, 'reg_alpha': 0.28699313743078597, 'reg_lambda': 0.191681450239306}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:57,372] Trial 15 finished with value: 0.8338945005611672 and parameters: {'n_estimators': 394, 'learning_rate': 0.182724421624754, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9181237670472284, 'colsample_bytree': 0.7597337594159317, 'gamma': 0.18076366582316777, 'reg_alpha': 0.6751198668748304, 'reg_lambda': 0.6247053891640286}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:57,870] Trial 16 finished with value: 0.8338945005611672 and parameters: {'n_estimators': 349, 'learning_rate': 0.26191430521096604, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.997959716819985, 'colsample_bytree': 0.8015688564877266, 'gamma': 0.2260148694968943, 'reg_alpha': 0.42823950637099184, 'reg_lambda': 0.005021616845949484}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:58,502] Trial 17 finished with value: 0.8294051627384961 and parameters: {'n_estimators': 304, 'learning_rate': 0.2144043702474172, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9584594502345722, 'colsample_bytree': 0.7425712117514462, 'gamma': 0.14549198051922327, 'reg_alpha': 0.231047250649405, 'reg_lambda': 0.2711346391485199}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:59,469] Trial 18 finished with value: 0.8260381593714928 and parameters: {'n_estimators': 354, 'learning_rate': 0.13759254307721785, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.8853896763498308, 'colsample_bytree': 0.809809208901834, 'gamma': 0.09611700477429239, 'reg_alpha': 0.15818279148041042, 'reg_lambda': 0.5678105377469984}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:58:59,806] Trial 19 finished with value: 0.8260381593714926 and parameters: {'n_estimators': 101, 'learning_rate': 0.16414377963142374, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.9667206000037742, 'colsample_bytree': 0.7150776726564444, 'gamma': 0.15986452122373482, 'reg_alpha': 0.389182236568701, 'reg_lambda': 0.39177439087295773}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:58:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:00,498] Trial 20 finished with value: 0.8316498316498316 and parameters: {'n_estimators': 295, 'learning_rate': 0.20901852287472267, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.9150871509238027, 'colsample_bytree': 0.7754308292813907, 'gamma': 0.23196182443793176, 'reg_alpha': 0.0068939867861073645, 'reg_lambda': 0.7984161721329751}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:01,059] Trial 21 finished with value: 0.8316498316498316 and parameters: {'n_estimators': 323, 'learning_rate': 0.2515676325944485, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9831301244009387, 'colsample_bytree': 0.7652623096595363, 'gamma': 0.1875333644433894, 'reg_alpha': 0.33413489928931783, 'reg_lambda': 0.35460874606147474}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:01,581] Trial 22 finished with value: 0.8372615039281707 and parameters: {'n_estimators': 319, 'learning_rate': 0.27729005852994865, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9753194571196367, 'colsample_bytree': 0.7866799321850448, 'gamma': 0.16145133763669342, 'reg_alpha': 0.2321121285744114, 'reg_lambda': 0.2403590061819258}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:02,222] Trial 23 finished with value: 0.8125701459034792 and parameters: {'n_estimators': 379, 'learning_rate': 0.29591235231034835, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9333252627094878, 'colsample_bytree': 0.8182636516867349, 'gamma': 0.12732252851889347, 'reg_alpha': 0.2248189085879797, 'reg_lambda': 0.13470625147364448}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:03,011] Trial 24 finished with value: 0.8271604938271605 and parameters: {'n_estimators': 356, 'learning_rate': 0.26032887967075935, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.9743544644105846, 'colsample_bytree': 0.8547268746454446, 'gamma': 0.08146868747838809, 'reg_alpha': 0.21001159806875375, 'reg_lambda': 0.24536591398959898}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:03,625] Trial 25 finished with value: 0.809203142536476 and parameters: {'n_estimators': 308, 'learning_rate': 0.22353036476867502, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9422469539063212, 'colsample_bytree': 0.7877776472191522, 'gamma': 0.1623993974223662, 'reg_alpha': 0.08148714592755316, 'reg_lambda': 0.07164447159467613}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:04,209] Trial 26 finished with value: 0.8383838383838383 and parameters: {'n_estimators': 334, 'learning_rate': 0.2715361187359724, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9030449900610792, 'colsample_bytree': 0.7436611839801944, 'gamma': 0.21093458105611881, 'reg_alpha': 0.519282597300579, 'reg_lambda': 0.4358398435771231}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:04,777] Trial 27 finished with value: 0.8260381593714928 and parameters: {'n_estimators': 340, 'learning_rate': 0.20411293864936825, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.8360913332829406, 'colsample_bytree': 0.7406510042174376, 'gamma': 0.2086272888442294, 'reg_alpha': 0.5982503721168115, 'reg_lambda': 0.4326080155946592}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:05,289] Trial 28 finished with value: 0.8316498316498316 and parameters: {'n_estimators': 373, 'learning_rate': 0.15583225089309902, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9049000220332305, 'colsample_bytree': 0.7508955944435436, 'gamma': 0.2620117872781633, 'reg_alpha': 0.6984927339429564, 'reg_lambda': 0.49051459599219743}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:05,753] Trial 29 finished with value: 0.8170594837261503 and parameters: {'n_estimators': 287, 'learning_rate': 0.2785132313425802, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.7948256627242091, 'colsample_bytree': 0.7239728812246029, 'gamma': 0.29931960732784146, 'reg_alpha': 0.5011123378912394, 'reg_lambda': 0.5919309932732044}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:06,351] Trial 30 finished with value: 0.8327721661054994 and parameters: {'n_estimators': 198, 'learning_rate': 0.017496996326854447, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.8839294763056705, 'colsample_bytree': 0.851780409189192, 'gamma': 0.21427184901511, 'reg_alpha': 0.4205704811964999, 'reg_lambda': 0.706846019629001}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:06,798] Trial 31 finished with value: 0.8406285072951739 and parameters: {'n_estimators': 332, 'learning_rate': 0.27459265760359675, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.972030596910335, 'colsample_bytree': 0.7846931170269521, 'gamma': 0.17005242033976659, 'reg_alpha': 0.36587120613644775, 'reg_lambda': 0.30230132349778654}. Best is trial 13 with value: 0.8417508417508417.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:07,322] Trial 32 finished with value: 0.8462401795735129 and parameters: {'n_estimators': 371, 'learning_rate': 0.23139905503070082, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9663841101536176, 'colsample_bytree': 0.8203379517193834, 'gamma': 0.1320073460167574, 'reg_alpha': 0.36112268337465814, 'reg_lambda': 0.32169472422277506}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:07,868] Trial 33 finished with value: 0.8350168350168351 and parameters: {'n_estimators': 375, 'learning_rate': 0.23786562652163182, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9618009632638346, 'colsample_bytree': 0.8193267136736111, 'gamma': 0.1189405326684809, 'reg_alpha': 0.3694356137965803, 'reg_lambda': 0.30319686419948166}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:08,328] Trial 34 finished with value: 0.8395061728395062 and parameters: {'n_estimators': 368, 'learning_rate': 0.229653302914944, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9970139010670572, 'colsample_bytree': 0.8323663371731176, 'gamma': 0.14303202274997148, 'reg_alpha': 0.2799064407543135, 'reg_lambda': 0.20521426290140465}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:08,886] Trial 35 finished with value: 0.819304152637486 and parameters: {'n_estimators': 341, 'learning_rate': 0.2981911639925682, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9376902466535535, 'colsample_bytree': 0.8616695258943513, 'gamma': 0.09158704083230834, 'reg_alpha': 0.458785721012987, 'reg_lambda': 0.1477871922518338}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:09,627] Trial 36 finished with value: 0.7957351290684623 and parameters: {'n_estimators': 274, 'learning_rate': 0.19891497691236484, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.7090559395010348, 'colsample_bytree': 0.8682715171187246, 'gamma': 0.06954114058689964, 'reg_alpha': 0.07290342298156682, 'reg_lambda': 0.34918646057166747}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:10,090] Trial 37 finished with value: 0.8327721661054994 and parameters: {'n_estimators': 307, 'learning_rate': 0.1721552325587411, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9758693718981786, 'colsample_bytree': 0.8364437822577447, 'gamma': 0.1704466887222677, 'reg_alpha': 0.3748923049160459, 'reg_lambda': 0.11955610271687367}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:10,764] Trial 38 finished with value: 0.8215488215488215 and parameters: {'n_estimators': 399, 'learning_rate': 0.25574379208232606, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.8587484938334778, 'colsample_bytree': 0.8107850212444511, 'gamma': 0.11837738313838067, 'reg_alpha': 0.5765353444897328, 'reg_lambda': 0.5396853522499382}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:11,384] Trial 39 finished with value: 0.8215488215488217 and parameters: {'n_estimators': 361, 'learning_rate': 0.2827512800742406, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9218182153014625, 'colsample_bytree': 0.7804562759719252, 'gamma': 0.14075116103484397, 'reg_alpha': 0.18170722056315236, 'reg_lambda': 0.9234059552865309}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:11,952] Trial 40 finished with value: 0.819304152637486 and parameters: {'n_estimators': 250, 'learning_rate': 0.21752426157631505, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9466593804492025, 'colsample_bytree': 0.8779289548567659, 'gamma': 0.03684968450394423, 'reg_alpha': 0.46602152967562505, 'reg_lambda': 0.31460320433164973}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:12,415] Trial 41 finished with value: 0.8316498316498316 and parameters: {'n_estimators': 367, 'learning_rate': 0.2315927732056179, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9963906569924749, 'colsample_bytree': 0.8980652644887744, 'gamma': 0.14482744535027356, 'reg_alpha': 0.2670036235088246, 'reg_lambda': 0.20318316317335564}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:12,903] Trial 42 finished with value: 0.8338945005611672 and parameters: {'n_estimators': 337, 'learning_rate': 0.1932700611969391, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.987145819297501, 'colsample_bytree': 0.8314383440373428, 'gamma': 0.12599927921706666, 'reg_alpha': 0.2784246933882676, 'reg_lambda': 0.21405376376315735}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:13,416] Trial 43 finished with value: 0.8338945005611672 and parameters: {'n_estimators': 380, 'learning_rate': 0.24353659786436505, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9672065043433581, 'colsample_bytree': 0.7954412928491699, 'gamma': 0.15262464689616703, 'reg_alpha': 0.3264819986802357, 'reg_lambda': 0.47270805388142406}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:13,837] Trial 44 finished with value: 0.8282828282828283 and parameters: {'n_estimators': 349, 'learning_rate': 0.22852798097106536, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.9971224174538336, 'colsample_bytree': 0.8257098538709635, 'gamma': 0.17283379195927834, 'reg_alpha': 0.39253520739427894, 'reg_lambda': 0.08191513543565532}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:14,364] Trial 45 finished with value: 0.8338945005611672 and parameters: {'n_estimators': 385, 'learning_rate': 0.2638171830725645, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9528530525391836, 'colsample_bytree': 0.763858308426532, 'gamma': 0.19414553933335782, 'reg_alpha': 0.2793248756588102, 'reg_lambda': 0.17495011535392066}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:14,877] Trial 46 finished with value: 0.8338945005611672 and parameters: {'n_estimators': 364, 'learning_rate': 0.2471782352733202, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.9842233110198297, 'colsample_bytree': 0.8433720065628747, 'gamma': 0.10085039260257259, 'reg_alpha': 0.12057189881720448, 'reg_lambda': 0.39807530513380834}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:15,259] Trial 47 finished with value: 0.8395061728395062 and parameters: {'n_estimators': 266, 'learning_rate': 0.2860779692317152, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9997901240112275, 'colsample_bytree': 0.8031091980392785, 'gamma': 0.1340739822641755, 'reg_alpha': 0.3575881838955419, 'reg_lambda': 0.282414548673367}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:15,677] Trial 48 finished with value: 0.8372615039281707 and parameters: {'n_estimators': 233, 'learning_rate': 0.17949126708431978, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9683791369889966, 'colsample_bytree': 0.942687941272609, 'gamma': 0.11215474408587531, 'reg_alpha': 0.8620990036272408, 'reg_lambda': 0.3302942201588725}. Best is trial 32 with value: 0.8462401795735129.\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Antony\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [13:59:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-05 13:59:16,306] Trial 49 finished with value: 0.8226711560044894 and parameters: {'n_estimators': 314, 'learning_rate': 0.0942389104199891, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.7806476191977008, 'colsample_bytree': 0.9232058886046421, 'gamma': 0.14999343096461912, 'reg_alpha': 0.18173642359578096, 'reg_lambda': 0.24900192802848994}. Best is trial 32 with value: 0.8462401795735129.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres : {'n_estimators': 371, 'learning_rate': 0.23139905503070082, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9663841101536176, 'colsample_bytree': 0.8203379517193834, 'gamma': 0.1320073460167574, 'reg_alpha': 0.36112268337465814, 'reg_lambda': 0.32169472422277506}\n",
      "Meilleur score CV : 0.8462401795735129\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 400),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 0.3),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    \n",
    "    # Moyenne des scores sur 3 folds\n",
    "    score = cross_val_score(model, x_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Création et lancement de l'étude\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # tu peux ajuster le nombre de trials\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(\"Meilleurs hyperparamètres :\", study.best_params)\n",
    "print(\"Meilleur score CV :\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6eeca",
   "metadata": {},
   "source": [
    "**Meilleurs paramètres selon Bayesian Optimization**\n",
    "\n",
    "| Paramètre | Valeur |\n",
    "|-----------|--------|\n",
    "| n_estimators | 371 |\n",
    "| learning_rate | 0.231 |\n",
    "| max_depth | 10 |\n",
    "| min_child_weight | 2 |\n",
    "| subsample | 0.966 |\n",
    "| colsample_bytree | 0.820 |\n",
    "| gamma | 0.132 |\n",
    "| reg_alpha | 0.361 |\n",
    "| reg_lambda | 0.322 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14333c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9494949494949495\n",
      "Confusion Matrix:\n",
      " [[539  10]\n",
      " [ 35 307]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       549\n",
      "           1       0.97      0.90      0.93       342\n",
      "\n",
      "    accuracy                           0.95       891\n",
      "   macro avg       0.95      0.94      0.95       891\n",
      "weighted avg       0.95      0.95      0.95       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(\n",
    "    learning_rate = 0.231,\n",
    "    n_estimators= 371,\n",
    "    max_depth= 10,\n",
    "    min_child_weight= 2,\n",
    "    gamma=0.132,                        \n",
    "    subsample=0.873,\n",
    "    colsample_bytree=0.758,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread= -1,\n",
    "    scale_pos_weight=1).fit(x_train, y_train)\n",
    "\n",
    "xgb_predictions = gbm.predict(x_test)\n",
    "predictions_train = gbm.predict(x_train)\n",
    "\n",
    "PassengerId = test['PassengerId']\n",
    "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId, 'Survived': xgb_predictions })\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "accuracy = accuracy_score(train['Survived'], predictions_train)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(train['Survived'], predictions_train))\n",
    "print(\"Classification Report:\\n\", classification_report(train['Survived'], predictions_train))\n",
    "\n",
    "StackingSubmission.to_csv('data/submissions/XGB_Bayesian.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
